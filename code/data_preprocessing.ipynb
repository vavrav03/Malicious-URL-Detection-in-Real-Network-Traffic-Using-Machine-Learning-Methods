{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e70b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.environment_specific import is_local_development\n",
    "from utils.dataset import load_public_dataset, load_full_private_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be37c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"grambeddings\": \"grambeddings\",\n",
    "    \"kaggle_binary\": \"kaggle_binary\",\n",
    "    \"kaggle_multiple\": \"kaggle_multiple\",\n",
    "    \"mendeley\": \"mendeley\",\n",
    "}\n",
    "dataset_names = datasets.keys()\n",
    "raw_folder = \"./data/raw\"\n",
    "target_folder = \"./data/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eccd485",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = []\n",
    "\n",
    "for dataset_name, _ in datasets.items():\n",
    "    dataset_path = os.path.join(raw_folder, dataset_name, \"dataset.csv\")\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    df = df[[\"url\", \"label\"]].copy()\n",
    "    df[\"dataset\"] = dataset_name  # use the dict key as the dataset identifier\n",
    "    all_dfs.append(df)\n",
    "\n",
    "if not is_local_development():\n",
    "    datasets[\"private_data\"] = \"private_data\"\n",
    "    \n",
    "\n",
    "all_datasets = pd.concat(all_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c38a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_count = len(all_datasets[\"dataset\"].unique())\n",
    "assert dataset_count == 4, \"Not all datasets were added to all_datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2896d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(dataset_name):\n",
    "    return all_datasets[all_datasets['dataset'] == dataset_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acef0755",
   "metadata": {},
   "source": [
    "# High level statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "434c58b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3507328 entries, 0 to 3507327\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Dtype \n",
      "---  ------   ----- \n",
      " 0   url      object\n",
      " 1   label    object\n",
      " 2   dataset  object\n",
      "dtypes: object(3)\n",
      "memory usage: 80.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://blog.sockpuppet.us/</td>\n",
       "      <td>benign</td>\n",
       "      <td>grambeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://blog.apiki.com/seguranca/</td>\n",
       "      <td>benign</td>\n",
       "      <td>grambeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://autoecole-lauriston.com/a/T0RVd056QXlNe...</td>\n",
       "      <td>malicious</td>\n",
       "      <td>grambeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://chinpay.site/index.html?hgcFSE@E$Z*DFcG...</td>\n",
       "      <td>malicious</td>\n",
       "      <td>grambeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.firstfivenebraska.org/blog/article/...</td>\n",
       "      <td>benign</td>\n",
       "      <td>grambeddings</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url      label       dataset\n",
       "0                        https://blog.sockpuppet.us/     benign  grambeddings\n",
       "1                  https://blog.apiki.com/seguranca/     benign  grambeddings\n",
       "2  http://autoecole-lauriston.com/a/T0RVd056QXlNe...  malicious  grambeddings\n",
       "3  http://chinpay.site/index.html?hgcFSE@E$Z*DFcG...  malicious  grambeddings\n",
       "4  http://www.firstfivenebraska.org/blog/article/...     benign  grambeddings"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(all_datasets.info())\n",
    "display(all_datasets.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27b42caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset: grambeddings ===\n",
      "            count  %_dataset  %_joined_dataset\n",
      "benign     400001       50.0             11.40\n",
      "malicious  399995       50.0             11.40\n",
      "TOTAL      799996      100.0             22.81\n",
      "\n",
      "=== Dataset: kaggle_binary ===\n",
      "            count  %_dataset  %_joined_dataset\n",
      "benign     316252       50.0              9.02\n",
      "malicious  316251       50.0              9.02\n",
      "TOTAL      632503      100.0             18.03\n",
      "\n",
      "=== Dataset: kaggle_multiple ===\n",
      "             count  %_dataset  %_joined_dataset\n",
      "benign      342651      66.81              9.77\n",
      "defacement   76252      14.87              2.17\n",
      "phishing     75135      14.65              2.14\n",
      "malware      18857       3.68              0.54\n",
      "TOTAL       512895     100.00             14.62\n",
      "\n",
      "=== Dataset: mendeley ===\n",
      "             count  %_dataset  %_joined_dataset\n",
      "benign     1526619      97.74             43.53\n",
      "malicious    35315       2.26              1.01\n",
      "TOTAL      1561934     100.00             44.53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in dataset_names:\n",
    "    df_subset = all_datasets[all_datasets[\"dataset\"] == name]\n",
    "    count = df_subset[\"label\"].value_counts()\n",
    "    percent = (count / len(df_subset) * 100).round(2)\n",
    "    percent_of_all = (count / len(all_datasets) * 100).round(2)\n",
    "\n",
    "    summary = pd.DataFrame({\"count\": count, \"%_dataset\": percent, \"%_joined_dataset\": percent_of_all})\n",
    "\n",
    "    total_row = pd.DataFrame(\n",
    "        {\"count\": [len(df_subset)], \"%_dataset\": [100.0], \"%_joined_dataset\": [len(df_subset) / len(all_datasets) * 100]},\n",
    "        index=[\"TOTAL\"],\n",
    "    )\n",
    "\n",
    "    summary = pd.concat([summary, total_row])\n",
    "\n",
    "    print(f\"=== Dataset: {name} ===\")\n",
    "    print(summary.round(2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369d88ff",
   "metadata": {},
   "source": [
    "# Removal of data\n",
    "- Everything related to removing records form any dataset is in this section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a9d215",
   "metadata": {},
   "source": [
    "## Remove rows with conflicting labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e237e1",
   "metadata": {},
   "source": [
    "- When we manually inspect generated csv files, we see that most of the conflict invovle Mendeley dataset. \n",
    "    - Also most amount of duplicates comes from here - this is crawled by https://developers.google.com/safe-browsing so it was possibly run multiple times and maybe made a mistake\n",
    "    - It either first classified as bening and then corrected to malignant or the other way\n",
    "- There is no temporal information in data, so we do not know which way the error originated - safest would be to remove them altogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a3cb9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conflicting_label_indices(df):\n",
    "    conflicting_urls = df.groupby(\"url\")[\"label\"].nunique()\n",
    "    conflicting_urls = conflicting_urls[conflicting_urls > 1].index\n",
    "    indices = df[df[\"url\"].isin(conflicting_urls)].index\n",
    "\n",
    "    repetition_counts = df[df[\"url\"].isin(conflicting_urls)].groupby(\"url\").size()\n",
    "    grouped_repetition = repetition_counts.value_counts().sort_index()\n",
    "\n",
    "    print(f\"Number of records to remove: {len(indices)}\")\n",
    "    print(f\"Number of unique URLs to remove: {len(conflicting_urls)}\")\n",
    "    print(\"Number of conflicting URLs grouped by how many times they are repeated:\")\n",
    "    print(grouped_repetition)\n",
    "\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ce4875",
   "metadata": {},
   "source": [
    "### Conflicting multi-class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc44dbb",
   "metadata": {},
   "source": [
    "- we first check whether there are any conflicts within the multiple datset\n",
    "- there are none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8c2fe10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records to remove: 0\n",
      "Number of unique URLs to remove: 0\n",
      "Number of conflicting URLs grouped by how many times they are repeated:\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "kaggle_multiple = all_datasets[all_datasets['dataset'] == datasets['kaggle_multiple']]\n",
    "to_remove_indices = get_conflicting_label_indices(kaggle_multiple)\n",
    "# nothing to remove\n",
    "del kaggle_multiple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0697ef45",
   "metadata": {},
   "source": [
    "- To do this correctly, we must rename phishing, defacement and malware labels from kaggle_multiple to malicious (kaggle_binary is created from this partially and this would cause label conflicts)\n",
    "- Mendeley dataset causes a lot of these misclassifications because of the nature of its collection\n",
    "    - Most is checked by https://developers.google.com/safe-browsing so it was possibly run multiple times and maybe made a mistake\n",
    "    - It either first classified as bening and then corrected to malignant or the other way\n",
    "- There is no temporal information in data, so we do not know which way the error originated - safest would be to remove them altogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffb2eabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records to remove: 215\n",
      "Number of unique URLs to remove: 105\n",
      "Number of conflicting URLs grouped by how many times they are repeated:\n",
      "2    100\n",
      "3      5\n",
      "Name: count, dtype: int64\n",
      "Dataset presence in conflicting records:\n",
      "dataset\n",
      "mendeley           195\n",
      "kaggle_binary       12\n",
      "kaggle_multiple      5\n",
      "grambeddings         3\n",
      "Name: count, dtype: int64\n",
      "Examples:\n",
      "                                           url      label          dataset\n",
      "845123             ebookstore.sony.com/reader/  malicious    kaggle_binary\n",
      "1712839            ebookstore.sony.com/reader/     benign  kaggle_multiple\n",
      "1540836           en.wikipedia.org/wiki/E-book     benign  kaggle_multiple\n",
      "1415800           en.wikipedia.org/wiki/E-book  malicious    kaggle_binary\n",
      "1534475  groups.yahoo.com/group/Band-in-a-Box/     benign  kaggle_multiple\n",
      "1090247  groups.yahoo.com/group/Band-in-a-Box/  malicious    kaggle_binary\n",
      "2259601       http://allyourtrekarebelongto.us  malicious         mendeley\n",
      "2235206       http://allyourtrekarebelongto.us     benign         mendeley\n",
      "2170401                http://docs.google.com/     benign         mendeley\n",
      "1085903                http://docs.google.com/  malicious    kaggle_binary\n",
      "3196183                   http://gayguide.net/     benign         mendeley\n",
      "3241949                   http://gayguide.net/  malicious         mendeley\n",
      "3124848          http://gaytoday.badpuppy.com/     benign         mendeley\n",
      "3177051          http://gaytoday.badpuppy.com/  malicious         mendeley\n",
      "1980525         http://kissgirltalk.tripod.com  malicious         mendeley\n",
      "3201301         http://kissgirltalk.tripod.com     benign         mendeley\n"
     ]
    }
   ],
   "source": [
    "def get_binary_named_dataset(df):\n",
    "    relabelled_df = df.copy()\n",
    "    relabelled_df[\"label\"] = np.where(df[\"label\"] == \"benign\", \"benign\", \"malicious\")\n",
    "    return relabelled_df\n",
    "\n",
    "relabelled_df = get_binary_named_dataset(all_datasets)\n",
    "\n",
    "conflicting_indices = get_conflicting_label_indices(relabelled_df)\n",
    "\n",
    "conflicting_records = relabelled_df.loc[conflicting_indices].sort_values(by=\"url\")\n",
    "print(\"Dataset presence in conflicting records:\")\n",
    "print(conflicting_records[\"dataset\"].value_counts())\n",
    "print(\"Examples:\")\n",
    "print(conflicting_records.head(16))\n",
    "\n",
    "before = len(all_datasets)\n",
    "all_datasets = all_datasets.drop(index=conflicting_indices).reset_index(drop=True)\n",
    "assert len(relabelled_df) - len(all_datasets) == len(conflicting_records)\n",
    "\n",
    "del relabelled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a0536c",
   "metadata": {},
   "source": [
    "## Remove defacement URLs\n",
    "- Defacement is a type of attack, which cannot be detected from just URL string (see thesis explanation)\n",
    "- Its inclusion in dataset would force the model to overfit or learn wrong information\n",
    "- --> Remove all defacement URLs from the kaggle_multiple dataset. \n",
    "- Since kaggle_binary is partially created from kaggle_multiple (see thesis), we also remove these from kaggle_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021d98a7",
   "metadata": {},
   "source": [
    "- First, look at how much content is shared between kaggle_binary and kaggle_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5236bd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total shared URLs: 170168\n",
      "% of kaggle_binary also present in kaggle_multiple: 26.90%\n",
      "% of kaggle_multiple also present in kaggle_binary: 33.18%\n",
      "\n",
      "=== kaggle_binary ===\n",
      "           total_count  shared_count  %shared_of_label\n",
      "label                                                 \n",
      "benign          316252           0.0              0.00\n",
      "malicious       316239      170168.0             53.81\n",
      "\n",
      "=== kaggle_multiple ===\n",
      "            total_count  shared_count  %shared_of_label\n",
      "label                                                  \n",
      "benign           342646           0.0              0.00\n",
      "defacement        76252       76230.0             99.97\n",
      "malware           18857       18853.0             99.98\n",
      "phishing          75135       75085.0             99.93\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_binary = all_datasets[all_datasets[\"dataset\"] == datasets[\"kaggle_binary\"]]\n",
    "df_multiple = all_datasets[all_datasets[\"dataset\"] == datasets[\"kaggle_multiple\"]]\n",
    "\n",
    "urls_binary = set(df_binary[\"url\"])\n",
    "urls_multiple = set(df_multiple[\"url\"])\n",
    "shared_urls = urls_binary.intersection(urls_multiple)\n",
    "print(f\"Total shared URLs: {len(shared_urls)}\")\n",
    "print(f\"% of kaggle_binary also present in kaggle_multiple: {len(shared_urls) / len(df_binary) * 100:.2f}%\")\n",
    "print(f\"% of kaggle_multiple also present in kaggle_binary: {len(shared_urls) / len(df_multiple) * 100:.2f}%\\n\")\n",
    "\n",
    "shared_df_binary = df_binary[df_binary[\"url\"].isin(shared_urls)]\n",
    "shared_df_multiple = df_multiple[df_multiple[\"url\"].isin(shared_urls)]\n",
    "\n",
    "\n",
    "def print_label_sharing_stats(name, full_df, shared_df):\n",
    "    full_counts = full_df[\"label\"].value_counts()\n",
    "    shared_counts = shared_df[\"label\"].value_counts()\n",
    "\n",
    "    summary = pd.DataFrame(\n",
    "        {\n",
    "            \"total_count\": full_counts,\n",
    "            \"shared_count\": shared_counts,\n",
    "        }\n",
    "    ).fillna(0)\n",
    "\n",
    "    summary[\"%shared_of_label\"] = (summary[\"shared_count\"] / summary[\"total_count\"] * 100).round(2)\n",
    "\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(summary)\n",
    "    print()\n",
    "\n",
    "\n",
    "print_label_sharing_stats(datasets[\"kaggle_binary\"], df_binary, shared_df_binary)\n",
    "print_label_sharing_stats(datasets[\"kaggle_multiple\"], df_multiple, shared_df_multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8381ad7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 152482 records associated with 'defacement' from 'kaggle_multiple' and duplicates.\n"
     ]
    }
   ],
   "source": [
    "defacement_urls = all_datasets.loc[\n",
    "    (all_datasets[\"dataset\"] == \"kaggle_multiple\") & (all_datasets[\"label\"] == \"defacement\"), \"url\"\n",
    "]\n",
    "\n",
    "all_datasets_filtered = all_datasets[~all_datasets[\"url\"].isin(defacement_urls)].reset_index(drop=True)\n",
    "\n",
    "print(\n",
    "    f\"Removed {len(all_datasets) - len(all_datasets_filtered)} records associated with 'defacement' from 'kaggle_multiple' and duplicates.\"\n",
    ")\n",
    "all_datasets = all_datasets_filtered\n",
    "del all_datasets_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8a1c78",
   "metadata": {},
   "source": [
    "## Within dataset duplication\n",
    "- we see that only for mendeley dataset, there are duplicates for non-processed URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5979ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "relabelled_df = get_binary_named_dataset(all_datasets.copy())\n",
    "\n",
    "def pct(n, d):\n",
    "    return 0 if d == 0 else n / d * 100\n",
    "\n",
    "result = []\n",
    "for dataset_name in dataset_names:\n",
    "    df = relabelled_df[relabelled_df['dataset'] == dataset_name]\n",
    "    records_count = len(df)\n",
    "    uniq_df = df.drop_duplicates(subset=[\"url\"])\n",
    "    unique_count = len(uniq_df)\n",
    "\n",
    "    duplicates_cnt = records_count - unique_count\n",
    "    duplicates_pct = pct(duplicates_cnt, records_count)\n",
    "\n",
    "    mal_df = df[df[\"label\"] == \"malicious\"]\n",
    "    ben_df = df[df[\"label\"] == \"benign\"]\n",
    "\n",
    "    result.append(\n",
    "        {\n",
    "            \"dataset\": dataset_name,\n",
    "            \"records_count\": records_count,\n",
    "            \"duplicates_count\": duplicates_cnt,\n",
    "            \"duplicates %\": duplicates_pct,\n",
    "            \"unique_count\": unique_count,\n",
    "            \"unique %\": pct(unique_count, records_count),\n",
    "            \"benign %\": pct(len(ben_df), records_count),\n",
    "            \"malicious %\": pct(len(mal_df), records_count),\n",
    "            \"unique_benign %\": pct(len(ben_df.drop_duplicates(subset=[\"url\"])), len(ben_df)),\n",
    "            \"unique_malicious %\": pct(len(mal_df.drop_duplicates(subset=[\"url\"])), len(mal_df)),\n",
    "        }\n",
    "    )\n",
    "\n",
    "all_datasets.drop_duplicates(subset=[\"dataset\", \"url\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc8ba19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 47637\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>records_count</th>\n",
       "      <th>duplicates_count</th>\n",
       "      <th>duplicates %</th>\n",
       "      <th>unique_count</th>\n",
       "      <th>unique %</th>\n",
       "      <th>benign %</th>\n",
       "      <th>malicious %</th>\n",
       "      <th>unique_benign %</th>\n",
       "      <th>unique_malicious %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grambeddings</td>\n",
       "      <td>799993</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>799993</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.000188</td>\n",
       "      <td>49.999812</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kaggle_binary</td>\n",
       "      <td>556261</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>556261</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>56.853168</td>\n",
       "      <td>43.146832</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kaggle_multiple</td>\n",
       "      <td>436638</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>436638</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>78.473701</td>\n",
       "      <td>21.526299</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mendeley</td>\n",
       "      <td>1561739</td>\n",
       "      <td>47637</td>\n",
       "      <td>3.050254</td>\n",
       "      <td>1514102</td>\n",
       "      <td>96.949746</td>\n",
       "      <td>97.744694</td>\n",
       "      <td>2.255306</td>\n",
       "      <td>96.892599</td>\n",
       "      <td>99.426495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dataset  records_count  duplicates_count  duplicates %  \\\n",
       "0     grambeddings         799993                 0      0.000000   \n",
       "1    kaggle_binary         556261                 0      0.000000   \n",
       "2  kaggle_multiple         436638                 0      0.000000   \n",
       "3         mendeley        1561739             47637      3.050254   \n",
       "\n",
       "   unique_count    unique %   benign %  malicious %  unique_benign %  \\\n",
       "0        799993  100.000000  50.000188    49.999812       100.000000   \n",
       "1        556261  100.000000  56.853168    43.146832       100.000000   \n",
       "2        436638  100.000000  78.473701    21.526299       100.000000   \n",
       "3       1514102   96.949746  97.744694     2.255306        96.892599   \n",
       "\n",
       "   unique_malicious %  \n",
       "0          100.000000  \n",
       "1          100.000000  \n",
       "2          100.000000  \n",
       "3           99.426495  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Removed {len(relabelled_df) - len(all_datasets)}\")\n",
    "display(pd.DataFrame(result))\n",
    "del relabelled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f4499c",
   "metadata": {},
   "source": [
    "# Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "321d5973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from utils.url_features import gini_coefficient\n",
    "from utils.dataset import analyze_folds\n",
    "\n",
    "def assign_folds(dataset, domain_stats: pd.DataFrame, n_folds: int = 5, seed: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Greedy assignment that balances total_records first, malicious count second.\n",
    "    Complexity: O(D log F) where D = #domains, F = #folds.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    shuffled = domain_stats.sample(frac=1, random_state=seed)\n",
    "    # (total - first criterion, malicious_count - second criterion, i)\n",
    "    heap = [(0, 0, i) for i in range(n_folds)]\n",
    "    heapq.heapify(heap)\n",
    "\n",
    "    domain, fold = [], []\n",
    "    for d, total, malicious in shuffled[[\"sld\", \"total_records\", \"malicious\"]].to_numpy():\n",
    "        total_f, malicious_f, fid = heapq.heappop(heap)\n",
    "        domain.append(d)\n",
    "        fold.append(fid)\n",
    "        heapq.heappush(heap, (total_f + total, malicious_f + malicious, fid))\n",
    "\n",
    "    assigned = pd.DataFrame({'sld': domain, 'fold': fold})\n",
    "    assigned = assigned.merge(domain_stats[[\"sld\", \"total_records\"]], on=\"sld\", how=\"left\")\n",
    "    gini_per_fold = assigned.groupby(\"fold\")[\"total_records\"].apply(lambda arr: gini_coefficient(arr.values))\n",
    "\n",
    "    # outlier-heavy first\n",
    "    new_order = (\n",
    "        gini_per_fold.sort_values(ascending=False)  \n",
    "        .reset_index()\n",
    "        .assign(new_fold=lambda d: d.index)\n",
    "    )\n",
    "    remap = dict(zip(new_order[\"fold\"], new_order[\"new_fold\"]))\n",
    "    assigned[\"fold\"] = assigned[\"fold\"].map(remap)\n",
    "\n",
    "    grambeddigns_folds = dataset.merge(assigned, on='sld', how='left')\n",
    "\n",
    "    return grambeddigns_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10253551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import get_domain_stats\n",
    "from utils.url_features import get_sld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4287202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets['sld'] = all_datasets['url'].apply(get_sld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6036ebcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== grambeddings ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>total</th>\n",
       "      <th>unique_domains</th>\n",
       "      <th>benign</th>\n",
       "      <th>benign_pct</th>\n",
       "      <th>malicious</th>\n",
       "      <th>malicious_pct</th>\n",
       "      <th>top_1</th>\n",
       "      <th>top_2</th>\n",
       "      <th>top_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>159998</td>\n",
       "      <td>67929</td>\n",
       "      <td>70075</td>\n",
       "      <td>43.797422</td>\n",
       "      <td>89923</td>\n",
       "      <td>56.202578</td>\n",
       "      <td>000webhostapp (12.1%)</td>\n",
       "      <td>blogspot (2.8%)</td>\n",
       "      <td>duckdns (1.2%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>159998</td>\n",
       "      <td>77389</td>\n",
       "      <td>80077</td>\n",
       "      <td>50.048751</td>\n",
       "      <td>79921</td>\n",
       "      <td>49.951249</td>\n",
       "      <td>appspot (6.3%)</td>\n",
       "      <td>bandcamp (1.3%)</td>\n",
       "      <td>podbean (1.1%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>159999</td>\n",
       "      <td>77665</td>\n",
       "      <td>85930</td>\n",
       "      <td>53.706586</td>\n",
       "      <td>74069</td>\n",
       "      <td>46.293414</td>\n",
       "      <td>alibaba (5.3%)</td>\n",
       "      <td>platino (1.2%)</td>\n",
       "      <td>netlify (0.9%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>160000</td>\n",
       "      <td>82604</td>\n",
       "      <td>82363</td>\n",
       "      <td>51.476875</td>\n",
       "      <td>77637</td>\n",
       "      <td>48.523125</td>\n",
       "      <td>buap (1.8%)</td>\n",
       "      <td>weebly (0.8%)</td>\n",
       "      <td>libsyn (0.5%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>159998</td>\n",
       "      <td>82855</td>\n",
       "      <td>81553</td>\n",
       "      <td>50.971262</td>\n",
       "      <td>78445</td>\n",
       "      <td>49.028738</td>\n",
       "      <td>webcindario (1.7%)</td>\n",
       "      <td>69.167.151.209 (1.1%)</td>\n",
       "      <td>justns (1.0%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold   total  unique_domains  benign  benign_pct  malicious  malicious_pct  \\\n",
       "0     0  159998           67929   70075   43.797422      89923      56.202578   \n",
       "1     1  159998           77389   80077   50.048751      79921      49.951249   \n",
       "2     2  159999           77665   85930   53.706586      74069      46.293414   \n",
       "3     3  160000           82604   82363   51.476875      77637      48.523125   \n",
       "4     4  159998           82855   81553   50.971262      78445      49.028738   \n",
       "\n",
       "                   top_1                  top_2           top_3  \n",
       "0  000webhostapp (12.1%)        blogspot (2.8%)  duckdns (1.2%)  \n",
       "1         appspot (6.3%)        bandcamp (1.3%)  podbean (1.1%)  \n",
       "2         alibaba (5.3%)         platino (1.2%)  netlify (0.9%)  \n",
       "3            buap (1.8%)          weebly (0.8%)   libsyn (0.5%)  \n",
       "4     webcindario (1.7%)  69.167.151.209 (1.1%)   justns (1.0%)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== kaggle_binary ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>total</th>\n",
       "      <th>unique_domains</th>\n",
       "      <th>benign</th>\n",
       "      <th>benign_pct</th>\n",
       "      <th>malicious</th>\n",
       "      <th>malicious_pct</th>\n",
       "      <th>top_1</th>\n",
       "      <th>top_2</th>\n",
       "      <th>top_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>111245</td>\n",
       "      <td>31791</td>\n",
       "      <td>68194</td>\n",
       "      <td>61.300733</td>\n",
       "      <td>43051</td>\n",
       "      <td>38.699267</td>\n",
       "      <td>wikipedia (10.4%)</td>\n",
       "      <td>youtube (7.8%)</td>\n",
       "      <td>myspace (2.6%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>111245</td>\n",
       "      <td>33123</td>\n",
       "      <td>61248</td>\n",
       "      <td>55.056856</td>\n",
       "      <td>49997</td>\n",
       "      <td>44.943144</td>\n",
       "      <td>blogspot (5.6%)</td>\n",
       "      <td>linkedin (3.6%)</td>\n",
       "      <td>ietf (2.9%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>111245</td>\n",
       "      <td>34219</td>\n",
       "      <td>64168</td>\n",
       "      <td>57.681694</td>\n",
       "      <td>47077</td>\n",
       "      <td>42.318306</td>\n",
       "      <td>facebook (7.0%)</td>\n",
       "      <td>amazon (4.6%)</td>\n",
       "      <td>yahoo (4.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>111245</td>\n",
       "      <td>36308</td>\n",
       "      <td>62273</td>\n",
       "      <td>55.978246</td>\n",
       "      <td>48972</td>\n",
       "      <td>44.021754</td>\n",
       "      <td>imdb (3.1%)</td>\n",
       "      <td>answers (2.2%)</td>\n",
       "      <td>manta (1.9%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>111281</td>\n",
       "      <td>37131</td>\n",
       "      <td>60369</td>\n",
       "      <td>54.249153</td>\n",
       "      <td>50912</td>\n",
       "      <td>45.750847</td>\n",
       "      <td>mylife (2.5%)</td>\n",
       "      <td>000webhostapp (1.9%)</td>\n",
       "      <td>123people (1.7%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold   total  unique_domains  benign  benign_pct  malicious  malicious_pct  \\\n",
       "0     0  111245           31791   68194   61.300733      43051      38.699267   \n",
       "1     1  111245           33123   61248   55.056856      49997      44.943144   \n",
       "2     2  111245           34219   64168   57.681694      47077      42.318306   \n",
       "3     3  111245           36308   62273   55.978246      48972      44.021754   \n",
       "4     4  111281           37131   60369   54.249153      50912      45.750847   \n",
       "\n",
       "               top_1                 top_2             top_3  \n",
       "0  wikipedia (10.4%)        youtube (7.8%)    myspace (2.6%)  \n",
       "1    blogspot (5.6%)       linkedin (3.6%)       ietf (2.9%)  \n",
       "2    facebook (7.0%)         amazon (4.6%)      yahoo (4.0%)  \n",
       "3        imdb (3.1%)        answers (2.2%)      manta (1.9%)  \n",
       "4      mylife (2.5%)  000webhostapp (1.9%)  123people (1.7%)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== kaggle_multiple ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>total</th>\n",
       "      <th>unique_domains</th>\n",
       "      <th>benign</th>\n",
       "      <th>benign_pct</th>\n",
       "      <th>malware</th>\n",
       "      <th>malware_pct</th>\n",
       "      <th>phishing</th>\n",
       "      <th>phishing_pct</th>\n",
       "      <th>top_1</th>\n",
       "      <th>top_2</th>\n",
       "      <th>top_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>87293</td>\n",
       "      <td>20706</td>\n",
       "      <td>68789</td>\n",
       "      <td>78.802424</td>\n",
       "      <td>3126</td>\n",
       "      <td>3.581043</td>\n",
       "      <td>15378</td>\n",
       "      <td>17.616533</td>\n",
       "      <td>wikipedia (12.4%)</td>\n",
       "      <td>youtube (7.9%)</td>\n",
       "      <td>facebook (7.6%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>87328</td>\n",
       "      <td>24458</td>\n",
       "      <td>69716</td>\n",
       "      <td>79.832356</td>\n",
       "      <td>3182</td>\n",
       "      <td>3.643734</td>\n",
       "      <td>14430</td>\n",
       "      <td>16.523910</td>\n",
       "      <td>yahoo (5.3%)</td>\n",
       "      <td>amazon (4.8%)</td>\n",
       "      <td>imdb (3.2%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>87293</td>\n",
       "      <td>26008</td>\n",
       "      <td>67645</td>\n",
       "      <td>77.491895</td>\n",
       "      <td>5297</td>\n",
       "      <td>6.068070</td>\n",
       "      <td>14351</td>\n",
       "      <td>16.440035</td>\n",
       "      <td>linkedin (4.6%)</td>\n",
       "      <td>myspace (2.7%)</td>\n",
       "      <td>mixh (2.7%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>87393</td>\n",
       "      <td>26260</td>\n",
       "      <td>68249</td>\n",
       "      <td>78.094355</td>\n",
       "      <td>2964</td>\n",
       "      <td>3.391576</td>\n",
       "      <td>16180</td>\n",
       "      <td>18.514069</td>\n",
       "      <td>blogspot (7.7%)</td>\n",
       "      <td>answers (2.3%)</td>\n",
       "      <td>wn (1.8%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>87331</td>\n",
       "      <td>29516</td>\n",
       "      <td>68247</td>\n",
       "      <td>78.147508</td>\n",
       "      <td>4288</td>\n",
       "      <td>4.910055</td>\n",
       "      <td>14796</td>\n",
       "      <td>16.942437</td>\n",
       "      <td>ancestry (2.3%)</td>\n",
       "      <td>wordpress (1.7%)</td>\n",
       "      <td>googlegroups (1.4%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  total  unique_domains  benign  benign_pct  malware  malware_pct  \\\n",
       "0     0  87293           20706   68789   78.802424     3126     3.581043   \n",
       "1     1  87328           24458   69716   79.832356     3182     3.643734   \n",
       "2     2  87293           26008   67645   77.491895     5297     6.068070   \n",
       "3     3  87393           26260   68249   78.094355     2964     3.391576   \n",
       "4     4  87331           29516   68247   78.147508     4288     4.910055   \n",
       "\n",
       "   phishing  phishing_pct              top_1             top_2  \\\n",
       "0     15378     17.616533  wikipedia (12.4%)    youtube (7.9%)   \n",
       "1     14430     16.523910       yahoo (5.3%)     amazon (4.8%)   \n",
       "2     14351     16.440035    linkedin (4.6%)    myspace (2.7%)   \n",
       "3     16180     18.514069    blogspot (7.7%)    answers (2.3%)   \n",
       "4     14796     16.942437    ancestry (2.3%)  wordpress (1.7%)   \n",
       "\n",
       "                 top_3  \n",
       "0      facebook (7.6%)  \n",
       "1          imdb (3.2%)  \n",
       "2          mixh (2.7%)  \n",
       "3            wn (1.8%)  \n",
       "4  googlegroups (1.4%)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== mendeley ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>total</th>\n",
       "      <th>unique_domains</th>\n",
       "      <th>benign</th>\n",
       "      <th>benign_pct</th>\n",
       "      <th>malicious</th>\n",
       "      <th>malicious_pct</th>\n",
       "      <th>top_1</th>\n",
       "      <th>top_2</th>\n",
       "      <th>top_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>304794</td>\n",
       "      <td>141180</td>\n",
       "      <td>297977</td>\n",
       "      <td>97.763407</td>\n",
       "      <td>6817</td>\n",
       "      <td>2.236593</td>\n",
       "      <td>geocities (17.4%)</td>\n",
       "      <td>imdb (3.3%)</td>\n",
       "      <td>yahoo (3.2%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>302327</td>\n",
       "      <td>153900</td>\n",
       "      <td>295983</td>\n",
       "      <td>97.901610</td>\n",
       "      <td>6344</td>\n",
       "      <td>2.098390</td>\n",
       "      <td>angelfire (6.8%)</td>\n",
       "      <td>newadvent (3.9%)</td>\n",
       "      <td>gamespot (1.3%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>302327</td>\n",
       "      <td>174591</td>\n",
       "      <td>294585</td>\n",
       "      <td>97.439197</td>\n",
       "      <td>7742</td>\n",
       "      <td>2.560803</td>\n",
       "      <td>tripod (7.2%)</td>\n",
       "      <td>ietf (1.1%)</td>\n",
       "      <td>webring (0.8%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>302327</td>\n",
       "      <td>180016</td>\n",
       "      <td>295265</td>\n",
       "      <td>97.664119</td>\n",
       "      <td>7062</td>\n",
       "      <td>2.335881</td>\n",
       "      <td>freewebs (1.8%)</td>\n",
       "      <td>blogspot (1.6%)</td>\n",
       "      <td>gamespy (0.9%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>302327</td>\n",
       "      <td>181844</td>\n",
       "      <td>295272</td>\n",
       "      <td>97.666434</td>\n",
       "      <td>7055</td>\n",
       "      <td>2.333566</td>\n",
       "      <td>wikipedia (2.1%)</td>\n",
       "      <td>homestead (1.1%)</td>\n",
       "      <td>cstv (0.7%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold   total  unique_domains  benign  benign_pct  malicious  malicious_pct  \\\n",
       "0     0  304794          141180  297977   97.763407       6817       2.236593   \n",
       "1     1  302327          153900  295983   97.901610       6344       2.098390   \n",
       "2     2  302327          174591  294585   97.439197       7742       2.560803   \n",
       "3     3  302327          180016  295265   97.664119       7062       2.335881   \n",
       "4     4  302327          181844  295272   97.666434       7055       2.333566   \n",
       "\n",
       "               top_1             top_2            top_3  \n",
       "0  geocities (17.4%)       imdb (3.3%)     yahoo (3.2%)  \n",
       "1   angelfire (6.8%)  newadvent (3.9%)  gamespot (1.3%)  \n",
       "2      tripod (7.2%)       ietf (1.1%)   webring (0.8%)  \n",
       "3    freewebs (1.8%)   blogspot (1.6%)   gamespy (0.9%)  \n",
       "4   wikipedia (2.1%)  homestead (1.1%)      cstv (0.7%)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_datasets_copy = []\n",
    "for dataset_name in dataset_names:\n",
    "    print(f\"=== {dataset_name} ===\")\n",
    "    df = get_dataset(dataset_name)\n",
    "    df_domain_stats = df\n",
    "    if dataset_name == datasets[\"kaggle_multiple\"]:\n",
    "        df_domain_stats = get_binary_named_dataset(df)\n",
    "    dataset = assign_folds(df, domain_stats=get_domain_stats(df_domain_stats))\n",
    "    display(analyze_folds(dataset))\n",
    "    dataset[\"dataset\"] = dataset_name\n",
    "    all_datasets_copy.append(dataset)\n",
    "\n",
    "all_datasets = pd.concat(all_datasets_copy, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d0de54",
   "metadata": {},
   "source": [
    "# Store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cc4faac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_result(dataset_subset):\n",
    "    assert {\"url\", \"label\", \"fold\", \"dataset\"}.issubset(dataset_subset.columns), \"Missing required columns\"\n",
    "    \n",
    "    dataset_name = dataset_subset[\"dataset\"].unique()\n",
    "    assert len(dataset_name) == 1, \"dataset_subset must contain only one dataset\"\n",
    "    dataset_name = dataset_name[0]\n",
    "\n",
    "    train_df = dataset_subset[dataset_subset[\"fold\"].isin([0, 1, 2, 3])][[\"url\", \"label\", \"fold\"]].reset_index(drop=True)\n",
    "    test_df = dataset_subset[dataset_subset[\"fold\"] == 4][[\"url\", \"label\", \"fold\"]].reset_index(drop=True)\n",
    "\n",
    "    ds_folder = os.path.join(\"data/processed\", dataset_name)\n",
    "    os.makedirs(ds_folder, exist_ok=True)\n",
    "\n",
    "    train_df.to_csv(os.path.join(ds_folder, \"train.csv\"), index=False)\n",
    "    test_df.to_csv(os.path.join(ds_folder, \"test.csv\"), index=False)\n",
    "\n",
    "    print(f\"Stored: {dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4a7c1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored: grambeddings\n",
      "Stored: kaggle_binary\n",
      "Stored: kaggle_multiple\n",
      "Stored: mendeley\n"
     ]
    }
   ],
   "source": [
    "for ds_name in all_datasets[\"dataset\"].unique():\n",
    "    subset = all_datasets[all_datasets[\"dataset\"] == ds_name]\n",
    "    store_result(subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f7a6fe",
   "metadata": {},
   "source": [
    "# Create joined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c835b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_dataset = all_datasets[all_datasets['dataset'] != datasets['kaggle_multiple']]\n",
    "joined_dataset = joined_dataset.drop(columns=[\"fold\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dc7eef",
   "metadata": {},
   "source": [
    "- there are no conflicts now (removed previously), so we can just drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fefa8d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_dataset = joined_dataset.drop_duplicates(subset=[\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff450162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2862060 entries, 0 to 3306993\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Dtype \n",
      "---  ------         ----- \n",
      " 0   url            object\n",
      " 1   label          object\n",
      " 2   dataset        object\n",
      " 3   sld            object\n",
      " 4   total_records  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 131.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "benign       2194899\n",
       "malicious     667161\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_dataset.info()\n",
    "joined_dataset[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7041c50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>total</th>\n",
       "      <th>unique_domains</th>\n",
       "      <th>benign</th>\n",
       "      <th>benign_pct</th>\n",
       "      <th>malicious</th>\n",
       "      <th>malicious_pct</th>\n",
       "      <th>top_1</th>\n",
       "      <th>top_2</th>\n",
       "      <th>top_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>572662</td>\n",
       "      <td>245422</td>\n",
       "      <td>444298</td>\n",
       "      <td>77.584683</td>\n",
       "      <td>128364</td>\n",
       "      <td>22.415317</td>\n",
       "      <td>geocities (9.3%)</td>\n",
       "      <td>appspot (1.8%)</td>\n",
       "      <td>alibaba (1.5%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>572351</td>\n",
       "      <td>255202</td>\n",
       "      <td>449272</td>\n",
       "      <td>78.495888</td>\n",
       "      <td>123079</td>\n",
       "      <td>21.504112</td>\n",
       "      <td>tripod (4.1%)</td>\n",
       "      <td>wikipedia (3.1%)</td>\n",
       "      <td>blogspot (2.7%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>572349</td>\n",
       "      <td>264155</td>\n",
       "      <td>444623</td>\n",
       "      <td>77.683896</td>\n",
       "      <td>127726</td>\n",
       "      <td>22.316104</td>\n",
       "      <td>angelfire (3.9%)</td>\n",
       "      <td>yahoo (2.5%)</td>\n",
       "      <td>imdb (2.3%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>572349</td>\n",
       "      <td>274267</td>\n",
       "      <td>414583</td>\n",
       "      <td>72.435350</td>\n",
       "      <td>157766</td>\n",
       "      <td>27.564650</td>\n",
       "      <td>000webhostapp (3.7%)</td>\n",
       "      <td>ietf (1.1%)</td>\n",
       "      <td>sourceforge (0.8%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>572349</td>\n",
       "      <td>281081</td>\n",
       "      <td>442123</td>\n",
       "      <td>77.247099</td>\n",
       "      <td>130226</td>\n",
       "      <td>22.752901</td>\n",
       "      <td>newadvent (2.0%)</td>\n",
       "      <td>google (0.6%)</td>\n",
       "      <td>about (0.6%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold   total  unique_domains  benign  benign_pct  malicious  malicious_pct  \\\n",
       "0     0  572662          245422  444298   77.584683     128364      22.415317   \n",
       "1     1  572351          255202  449272   78.495888     123079      21.504112   \n",
       "2     2  572349          264155  444623   77.683896     127726      22.316104   \n",
       "3     3  572349          274267  414583   72.435350     157766      27.564650   \n",
       "4     4  572349          281081  442123   77.247099     130226      22.752901   \n",
       "\n",
       "                  top_1             top_2               top_3  \n",
       "0      geocities (9.3%)    appspot (1.8%)      alibaba (1.5%)  \n",
       "1         tripod (4.1%)  wikipedia (3.1%)     blogspot (2.7%)  \n",
       "2      angelfire (3.9%)      yahoo (2.5%)         imdb (2.3%)  \n",
       "3  000webhostapp (3.7%)       ietf (1.1%)  sourceforge (0.8%)  \n",
       "4      newadvent (2.0%)     google (0.6%)        about (0.6%)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "joined_dataset = assign_folds(joined_dataset, domain_stats=get_domain_stats(joined_dataset))\n",
    "display(analyze_folds(joined_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a60f44",
   "metadata": {},
   "source": [
    "- we can see that the old datasets are pretty well distributed across new folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4aaa1594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold        dataset  proportion\n",
      "0      0   grambeddings    0.279215\n",
      "1      0  kaggle_binary    0.176958\n",
      "2      0       mendeley    0.543827\n",
      "3      1   grambeddings    0.265073\n",
      "4      1  kaggle_binary    0.206842\n",
      "5      1       mendeley    0.528085\n",
      "6      2   grambeddings    0.265888\n",
      "7      2  kaggle_binary    0.202794\n",
      "8      2       mendeley    0.531317\n",
      "9      3   grambeddings    0.310961\n",
      "10     3  kaggle_binary    0.193427\n",
      "11     3       mendeley    0.495612\n",
      "12     4   grambeddings    0.276445\n",
      "13     4  kaggle_binary    0.177942\n",
      "14     4       mendeley    0.545613\n"
     ]
    }
   ],
   "source": [
    "fold_counts = []\n",
    "for fold in sorted(joined_dataset[\"fold\"].unique()):\n",
    "    vc = joined_dataset.loc[joined_dataset[\"fold\"] == fold, \"dataset\"].value_counts(normalize=True)\n",
    "    for label, proportion in vc.items():\n",
    "        fold_counts.append({\"fold\": fold, \"dataset\": label, \"proportion\": proportion})\n",
    "\n",
    "df_counts = pd.DataFrame(fold_counts).sort_values([\"fold\", \"dataset\"]).reset_index(drop=True)\n",
    "print(df_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48a1937d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored: joined\n"
     ]
    }
   ],
   "source": [
    "joined_dataset['dataset'] = 'joined'\n",
    "store_result(joined_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b747608",
   "metadata": {},
   "source": [
    "- script that compares the output versions of datasets\n",
    "- useful when making changes to this code (check that the content remains the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c41770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grambeddings/test.csv: OK\n",
      "grambeddings/train.csv: OK\n",
      "joined/test.csv: OK\n",
      "joined/train.csv: OK\n",
      "kaggle_binary/test.csv: OK\n",
      "kaggle_binary/train.csv: OK\n",
      "kaggle_multiple/test.csv: OK\n",
      "kaggle_multiple/train.csv: OK\n",
      "mendeley/test.csv: OK\n",
      "mendeley/train.csv: OK\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# base1 = \"./data/processed\"\n",
    "# base2 = \"./data/processed_copy\"\n",
    "\n",
    "# subfolders = [\n",
    "#     name for name in os.listdir(base1)\n",
    "#     if os.path.isdir(os.path.join(base1, name))\n",
    "# ]\n",
    "\n",
    "# for subfolder in sorted(subfolders):\n",
    "#     path1 = os.path.join(base1, subfolder)\n",
    "#     path2 = os.path.join(base2, subfolder)\n",
    "\n",
    "#     if not os.path.isdir(path2):\n",
    "#         print(f\"Missing in copy: {subfolder}\")\n",
    "#         continue\n",
    "\n",
    "#     files1 = set(os.listdir(path1))\n",
    "#     files2 = set(os.listdir(path2))\n",
    "\n",
    "#     common_files = files1 & files2\n",
    "\n",
    "#     for filename in sorted(common_files):\n",
    "#         file1 = os.path.join(path1, filename)\n",
    "#         file2 = os.path.join(path2, filename)\n",
    "\n",
    "#         try:\n",
    "#             with open(file1, \"r\", encoding=\"utf-8\") as f1, open(file2, \"r\", encoding=\"utf-8\") as f2:\n",
    "#                 lines1 = f1.readlines()\n",
    "#                 lines2 = f2.readlines()\n",
    "\n",
    "#             if lines1 == lines2:\n",
    "#                 print(f\"{subfolder}/{filename}: Identical\")\n",
    "#             else:\n",
    "#                 print(f\"{subfolder}/{filename}: Content differs (line-by-line)\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"{subfolder}/{filename}: Failed to read - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7c2f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
